{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-2 ChatOllama 프롬프트 구체화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/q193qt6n5blc2wppqrq7477r0000gn/T/ipykernel_41450/4108171166.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"exaone3.5:2.4b\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"exaone3.5:2.4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = llm.invoke(\"Retrieval-Augmented Generation(RAG) Pipeline은 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Retrieval-Augmented Generation (RAG) Pipeline은 자연어 처리(NLP) 분야에서 특히 복잡한 질의응답(QA) 및 생성 작업에 효과적으로 사용되는 기술입니다. 이 시스템은 두 주요 구성 요소를 중심으로 설계되어 있습니다:\\n\\n### 주요 구성 요소:\\n1. **지식베이스 (Knowledge Base)**:\\n   - **정의**: 다양한 형태의 정보가 저장된 데이터베이스입니다. 이 정보는 텍스트, 구조화된 데이터, 이미지 등 다양할 수 있습니다.\\n   - **역할**: 질문에 대한 직접적인 답변을 제공하거나 관련성 있는 정보를 검색하는 데 사용됩니다.\\n\\n2. **생성 모델 (Generation Model)**:\\n   - **정의**: 일반적인 자연어 생성 능력을 갖춘 모델로, 기존 텍스트 데이터를 기반으로 새로운 텍스트를 생성할 수 있습니다.\\n   - **역할**: 질문에 대한 창의적이고 맥락에 맞는 답변을 생성하는데 활용됩니다. 생성 모델은 지식베이스에서 제공된 정보를 기반으로 더욱 풍부하고 정확한 응답을 생성할 수 있습니다.\\n\\n### RAG Pipeline의 작동 방식:\\n1. **질문 이해**: 사용자의 질의(질문)가 입력됩니다.\\n2. **키워드 추출 및 검색**: 질문에서 핵심 키워드를 추출하고, 이를 바탕으로 지식베이스 내에서 관련 정보를 검색합니다.\\n3. **답변 융합**: 지식베이스에서 찾은 정보와 생성 모델의 이전 추론 결과를 결합하여 최종 답변을 생성합니다. 생성 모델은 검색된 정보를 통해 더욱 구체적이고 관련성 있는 답변을 생산합니다.\\n4. **출력**: 최종적으로 처리된 답변이 사용자에게 제공됩니다.\\n\\n### 장점:\\n- **융합된 정보 활용**: 질문에 대한 답변이 단순 텍스트 생성을 넘어, 저장된 지식과 최신 정보의 융합을 통해 더욱 풍부해집니다.\\n- **맥락 이해**: 생성 모델이 과거 추론 결과를 기억하고 업데이트함으로써 문맥 이해와 일관성 있는 답변을 제공합니다.\\n- **복잡한 질의 처리**: 다양한 형태의 데이터를 통합하여 복잡하고 다층적인 질문에도 효과적으로 대응할 수 있습니다.\\n\\nRAG 기술은 특히 도메인 특화 지식이 풍부한 환경에서 뛰어난 성능을 발휘하며, 인공지능 시스템의 질문응답 능력 향상에 중요한 역할을 합니다.', additional_kwargs={}, response_metadata={'model': 'exaone3.5:2.4b', 'created_at': '2025-02-05T05:55:27.424915Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 8021411041, 'load_duration': 20781416, 'prompt_eval_count': 51, 'prompt_eval_duration': 165000000, 'eval_count': 524, 'eval_duration': 7833000000}, id='run-92a090e2-6e48-42c9-8761-ed7d98507496-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
