{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-2 LCEL(LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-3 LCEL 파이프라인 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2진수 `101010`을 16진수로 변환하면 `2A`입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 319, 'total_tokens': 341, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CddkXLw8LOJkhdNCEwumyBMIbyR8Q', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--04657f2e-36dd-4123-8114-197662452a07-0', usage_metadata={'input_tokens': 319, 'output_tokens': 22, 'total_tokens': 341, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리들을 가져온다.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 단순한 파이프라인 예시\n",
    "simple_chain = (\n",
    "    ChatPromptTemplate.from_template(\"주어진 숫자 {number}를 2진수로 변환해주세요\")\n",
    "    | llm\n",
    "    | ChatPromptTemplate.from_template(\"다음 2진수를 16진수로 변환해주세요: {text}\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 파이프라인 실행\n",
    "result = simple_chain.invoke({\"number\": \"42\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-4 RunnableParallel을 활용한 병렬 체인 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': AIMessage(content='오늘 날씨가 좋아 공원에서 산책을 했고, 많은 사람들이 운동을 즐기고 있었습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 43, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BSI5zeQOS8285tSBVN1cj0u7TbHP1', 'finish_reason': 'stop', 'logprobs': None}, id='run-17b349c3-521b-4490-a022-d69d71469b26-0', usage_metadata={'input_tokens': 43, 'output_tokens': 25, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'sentiment': AIMessage(content='이 텍스트는 긍정적인 감정을 표현하고 있습니다. \"날씨가 좋아서\"와 \"즐겁게 운동하고 있었어요\"라는 표현에서 기분 좋은 분위기와 사람들의 즐거운 활동이 잘 드러납니다. 전반적으로 행복하고 긍정적인 경험을 담고 있는 내용입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 44, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'id': 'chatcmpl-BSI5z6WPtZQN2t5worwoW15dnrs1r', 'finish_reason': 'stop', 'logprobs': None}, id='run-47fdea8a-42ab-4b84-b951-ed2a0ba2abe5-0', usage_metadata={'input_tokens': 44, 'output_tokens': 72, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'keywords': AIMessage(content='주요 키워드: 오늘, 날씨, 공원, 산책, 많은 사람들, 즐겁게, 운동', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 47, 'total_tokens': 74, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BSI5zX1Mekk6yQj4mPOY4ri8sfbAx', 'finish_reason': 'stop', 'logprobs': None}, id='run-9b457a06-581f-4b12-8f00-b81800faf4d2-0', usage_metadata={'input_tokens': 47, 'output_tokens': 27, 'total_tokens': 74, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리들을 가져온다. \n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# 병렬 체인 구성\n",
    "analysis_chain = RunnableParallel(\n",
    "    summary=ChatPromptTemplate.from_template(\"다음 텍스트를 요약해주세요: {text}\") | llm,\n",
    "    sentiment=ChatPromptTemplate.from_template(\"다음 텍스트의 감정을 분석해주세요: {text}\") | llm,\n",
    "    keywords=ChatPromptTemplate.from_template(\"다음 텍스트의 주요 키워드를 추출해주세요: {text}\") | llm\n",
    ")\n",
    "\n",
    "# 모든 분석이 동시에 실행된다.\n",
    "result = analysis_chain.invoke({\n",
    "    \"text\": \"오늘은 날씨가 좋아서 공원에서 산책을 했습니다. 많은 사람들이 즐겁게 운동하고 있었어요.\"\n",
    "})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-5 RunnablePassthrough를 활용한 중간 결과 전달    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='## 분석 리포트\\n\\n### 1. 원본 텍스트\\n- **내용**: LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다. 다양한 컴포넌트를 제공하여 개발을 용이하게 합니다.\\n- **주요 포인트**:\\n  - LangChain은 LLM(대형 언어 모델) 애플리케이션 개발을 위한 프레임워크로, 개발자에게 다양한 컴포넌트를 제공하여 개발 과정을 간소화합니다.\\n\\n### 2. 요약\\n- **내용**: LangChain은 LLM 애플리케이션 개발을 위한 다양한 컴포넌트를 제공하는 프레임워크입니다.\\n- **변경 사항**:\\n  - 원본 텍스트의 핵심 정보를 유지하면서 문장을 간결하게 재구성하였습니다.\\n  - \"개발을 용이하게 합니다\"라는 표현이 \"다양한 컴포넌트를 제공하는\"으로 대체되어, 요약이 더 명확하고 직관적으로 전달됩니다.\\n\\n### 3. 메타데이터 분석\\n- **토큰 사용량**:\\n  - **총 토큰 수**: 77\\n    - **프롬프트 토큰**: 49\\n    - **완료 토큰**: 28\\n- **모델 정보**:\\n  - **모델 이름**: gpt-4o-mini-2024-07-18\\n  - **시스템 지문**: fp_0392822090\\n- **완료 이유**: \\'stop\\' - 모델이 자연스럽게 응답을 마쳤음을 나타냅니다.\\n\\n### 4. 사용 메타데이터\\n- **입력 토큰**: 49\\n- **출력 토큰**: 28\\n- **입력 토큰 세부사항**: \\n  - 오디오 관련 토큰: 0\\n  - 캐시 읽기 토큰: 0\\n- **출력 토큰 세부사항**: \\n  - 오디오 관련 토큰: 0\\n  - 추론 관련 토큰: 0\\n\\n### 5. 결론\\n- LangChain에 대한 설명이 명확하고 간결하게 요약되었습니다. \\n- 메타데이터는 모델의 성능과 응답의 효율성을 보여주며, 입력과 출력의 토큰 수가 적절하게 관리되고 있음을 나타냅니다. \\n- 전반적으로, 원본 텍스트의 핵심 메시지를 효과적으로 전달하는 요약이 이루어졌습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 546, 'prompt_tokens': 352, 'total_tokens': 898, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BSI8n2jDqh8vVENYurZxLMPS5cX5m', 'finish_reason': 'stop', 'logprobs': None}, id='run-4268320a-5e92-4d9a-bb51-19aecdc33a24-0', usage_metadata={'input_tokens': 352, 'output_tokens': 546, 'total_tokens': 898, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리들을 가져온다.\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# 중간 결과를 활용하는 체인\n",
    "analysis_chain = (\n",
    "    {\n",
    "        \"original\": RunnablePassthrough(),  # 원본 입력을 보존\n",
    "        \"summary\": ChatPromptTemplate.from_template(\"{text}를 한 문장으로 요약해주세요\") | llm\n",
    "    }\n",
    "    | ChatPromptTemplate.from_template(\"\"\"\n",
    "원본 텍스트: {original}\n",
    "요약: {summary}\n",
    "\n",
    "위 내용에 대한 분석 리포트를 작성해주세요.\n",
    "    \"\"\")\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 체인 실행\n",
    "result = analysis_chain.invoke({\n",
    "    \"text\": \"LangChain은 LLM 애플리케이션 개발을 위한 프레임워크입니다. 다양한 컴포넌트를 제공하여 개발을 용이하게 합니다.\"\n",
    "})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-6 retriever 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리들을 가져온다\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# 환경변수 파일(.env)을 불러온다.\n",
    "load_dotenv()\n",
    "\n",
    "# 업스테이지의 임베딩 모델을 초기화한다.\n",
    "embedding = OpenAIEmbeddings(\n",
    "    base_url='https://api.upstage.ai/v1/solar',\n",
    "    api_key=os.getenv(\"UPSTAGE_API_KEY\"),\n",
    "    model='embedding-passage',\n",
    "    check_embedding_ctx_length=False\n",
    ")\n",
    "\n",
    "# Chroma 벡터 저장소를 초기화한다.\n",
    "vector_store = Chroma(\n",
    "                  embedding_function=embedding,\n",
    "                  collection_name='tax-markdown', \n",
    "                  persist_directory=\"./tax-markdown\")\n",
    "\n",
    "# retriever를 설정하고 상위 3개 결과를 반환하도록 한다.\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-7 LangChain허브에서 프롬프트 불러오기     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkang/personal/langgraph-book/.venv/lib/python3.12/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리들을 가져온다.\n",
    "from langsmith import Client\n",
    "\n",
    "# LangChain 허브에서 RAG 프롬프트 템플릿을 가져온다.\n",
    "client = Client()\n",
    "rag_prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)\n",
    "\n",
    "# 여러 문서들을 하나의 문자열로 결합하는 헬퍼 함수다.\n",
    "# 각 문서는 두 줄의 개행으로 구분되어 LLM이 문맥을 더 잘 파악할 수 있다.\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-8 LCEL을 활용한 과세 표준 체인 생성     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL의 기본 컴포넌트들을 가져온다.\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# RAG 체인을 구성한다.\n",
    "# 1. retriever로 문서를 가져와서 포매팅한다.\n",
    "# 2. 프롬프트에 문서와 질문을 전달한다.\n",
    "# 3. LLM으로 답변을 생성한다.\n",
    "# 4. 문자열로 파싱한다.\n",
    "tax_base_chain = (\n",
    "   {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "   | rag_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-9 과세 표준 체인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주택에 대한 종합부동산세 과세표준은 납세의무자가 보유한 주택의 공시가격을 합산한 금액에서 일정 금액(1세대 1주택자: 12억 원, 그 외: 9억 원 등)을 공제한 후, 공정시장가액비율(60~100%)을 곱하여 계산합니다. 공제 금액과 비율은 납세자의 상황에 따라 다릅니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tax_base_chain 활용을 위한 질문 작성\n",
    "tax_base_question = \"주택에 대한 종합부동산세 과세표준을 계산하는 방법은 무엇인가요?\"\n",
    "\n",
    "# tax_base_chain 실행\n",
    "tax_base_response = tax_base_chain.invoke(tax_base_question)\n",
    "tax_base_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-10 과세 표준 체인 프롬프트 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주택에 대한 종합부동산세 과세표준 = (주택의 공시가격 합산 - 공제금액) × 공정시장가액비율'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tax_base_chain 활용을 위한 프롬프트 수정\n",
    "tax_base_question = \"주택에 대한 종합부동산세 과세표준을 계산하는 방법을 수식으로 표현해서 수식만 반환해주세요. 부연설명을 하지 말아주세요\"\n",
    "\n",
    "# tax_base_chain 실행\n",
    "tax_base_response = tax_base_chain.invoke(tax_base_question)\n",
    "tax_base_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-11 공제액 계산 체인 생성 및 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주택에 대한 종합부동산세 과세표준의 공제액은 1세대 1주택자의 경우 12억 원, 법인 또는 법인으로 보는 단체의 경우 0원, 그 외의 경우 9억 원입니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 라이브러리들을 가져온다.\n",
    "from langsmith import Client\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LangChain 허브에서 RAG 프롬프트 템플릿을 가져온다.\n",
    "client = Client()\n",
    "rag_prompt = client.pull_prompt(\"rlm/rag-prompt\", include_model=True)\n",
    "\n",
    "\n",
    "# 검색된 문서들을 하나의 텍스트로 결합하는 함수를 정의한다.\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 종합부동산세 공제액 계산을 위한 RAG 체인을 구성한다.\n",
    "tax_deductible_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 공제액 관련 질문을 정의하고 체인을 실행한다.\n",
    "deductible_question = \"주택에 대한 종합부동산세 과세표준의 공제액을 알려주세요\"\n",
    "tax_deductible_response = tax_deductible_chain.invoke(deductible_question)\n",
    "tax_deductible_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-12 중간값을 활용한 LCEL 체인 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9억원'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 종부세 공제액 계산을 위한 프롬프트 템플릿을 정의한다.\n",
    "# Context에는 주택 수별 공제액 정보가 들어가고, Question에는 사용자의 질문이 들어간다.\n",
    "# 프롬프트는 금액만 반환하도록 명확히 지시한다.\n",
    "question = \"10억짜리 집을 2채 가지고 있을 때 세금을 얼마나 내나요?\"\n",
    "\n",
    "user_deduction_prompt = \"\"\"아래 [Context]는 주택에 대한 종합부동산세의 공제액에 관한 내용입니다.\n",
    "사용자의 질문을 통해서 가지고 있는 주택수에 대한 공제액이 얼마인지 금액만 반환해주세요\n",
    "\n",
    "[Context]\n",
    "{tax_deductible_response}\n",
    "\n",
    "[Question]\n",
    "질문: {question}\n",
    "답변:\n",
    "\"\"\"\n",
    "\n",
    "# PromptTemplate을 사용해 프롬프트의 변수 부분을 정의한다.\n",
    "user_deduction_prompt_template = PromptTemplate(\n",
    "   template=user_deduction_prompt,\n",
    "   input_variables=['tax_deductible_response', 'question']\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿, LLM, 출력 파서를 연결하여 체인을 구성한다.\n",
    "user_deduction_chain = (user_deduction_prompt_template\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인을 실행하여 사용자의 질문에 대한 공제액을 계산한다.\n",
    "user_deduction = user_deduction_chain.invoke({\n",
    "   'tax_deductible_response': tax_deductible_response,\n",
    "   'question': question\n",
    "})\n",
    "\n",
    "# 계산된 공제액을 반환한다.\n",
    "user_deduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv add -q langchain-tavily langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-13 Tavily를 활용한 웹 검색 도구 활용   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For 2025, the standard fair market value ratio for real estate tax remains 60%. However, there are discussions about increasing it to 80%. The official rate is still 60% as of November 2025.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# 환경변수 파일(.env)을 불러온다.\n",
    "load_dotenv()\n",
    "\n",
    "# Tavily 검색 도구를 초기화한다.\n",
    "search = TavilySearch(\n",
    "    include_answer=True, # AI가 검색 결과를 기반으로 답변을 반환한다\n",
    ")\n",
    "\n",
    "# 현재 연도의 공정시장가액비율을 검색한다.\n",
    "# datetime.now()로 현재 연도를 동적으로 가져와서 검색어에 포함한다.\n",
    "market_value_rate_search = search.invoke(f\"{datetime.now().year}년도 공정시장가액비율은?\")\n",
    "\n",
    "# 검색 결과를 반환한다.\n",
    "market_value_rate_search = market_value_rate_search['answer']\n",
    "market_value_rate_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-14 공정시장가액비율 계산을 위한 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'공정시장가액비율: 60%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 공정시장가액비율 추출을 위한 프롬프트 템플릿을 정의한다.\n",
    "# Context에는 검색된 정보가 들어가고, 사용자의 질문을 바탕으로 해당하는 비율만 반환한다.\n",
    "# 프롬프트는 부가 설명 없이 비율만 반환하도록 명확히 지시한다.\n",
    "market_value_rate_prompt = PromptTemplate.from_template(\"\"\"아래 [Context]는 공정시장가액비율에 관한 내용입니다.\n",
    "당신에게 주어진 공정시장가액비율에 관한 내용을 기반으로, 사용자의 상황에 대한 공정시장가액비율을 알려주세요.\n",
    "별도의 설명 없이 공정시장가액비율만 알려주세요.\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question]\n",
    "질문: {question}\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "# 프롬프트 템플릿, LLM, 출력 파서를 연결하여 체인을 구성한다.\n",
    "market_value_rate_chain = (\n",
    "   market_value_rate_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인을 실행하여 검색 결과에서 사용자 상황에 맞는 공정시장가액비율을 추출한다.\n",
    "market_value_rate = market_value_rate_chain.invoke({'context': market_value_rate_search, 'question': question})\n",
    "market_value_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-15 체인 실행 결과 종합으로 최종 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10억 원짜리 집을 2채 소유하고 있는 경우, 납세의무자는 2주택 이하의 소유자로 분류됩니다. 따라서, 주택에 대한 종합부동산세를 계산하기 위해 다음 단계를 따릅니다.\\n\\n1. **주택의 공시가격 합산**: \\n   - 10억 원 + 10억 원 = 20억 원\\n\\n2. **과세표준 계산**:\\n   - 공제액: 1세대 2주택자의 경우 9억 원이 공제됩니다.\\n   - 과세표준 = (주택의 공시가격 합산 - 공제금액) × 공정시장가액비율\\n   - 과세표준 = (20억 원 - 9억 원) × 0.6 = 11억 원 × 0.6 = 6.6억 원\\n\\n3. **세액 계산**:\\n   - 과세표준 6.6억 원에 해당하는 세율을 적용합니다.\\n   - 6억 원 초과 12억 원 이하의 세율을 적용합니다:\\n     - 세액 = 360만 원 + (6억 원을 초과하는 금액의 1천분의 10)\\n     - 6.6억 원 - 6억 원 = 0.6억 원 = 6천만 원\\n     - 세액 = 360만 원 + (6천만 원 × 0.001) = 360만 원 + 60만 원 = 420만 원\\n\\n따라서, 10억 원짜리 집을 2채 소유하고 있을 때 납부해야 할 종합부동산세는 **420만 원**입니다.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 챗봇 형식의 프롬프트 템플릿을 생성한다.\n",
    "# system 메시지에는 세금 계산에 필요한 모든 기준 정보를 포함한다.\n",
    "# human 메시지에는 사용자의 질문이 들어간다.\n",
    "house_tax_prompt = ChatPromptTemplate.from_messages([\n",
    "   ('system', f'''과세표준 계산방법: {tax_base_response}\n",
    "공정시장가액비율: {market_value_rate}\n",
    "공제액: {tax_deductible_response}\n",
    "\n",
    "위의 공식과 아래 세율에 관한 정보를 활용해서 세금을 계산해주세요.\n",
    "세율: {{tax_rate}}\n",
    "'''),\n",
    "   ('human', '{question}')\n",
    "])\n",
    "\n",
    "house_tax_chain = (\n",
    "   {\n",
    "       'tax_rate': retriever | format_docs,\n",
    "       'question': RunnablePassthrough()\n",
    "   }\n",
    "   | house_tax_prompt\n",
    "   | llm\n",
    "   | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 체인을 실행하여 최종 세금을 계산한다.\n",
    "house_tax = house_tax_chain.invoke(question)\n",
    "house_tax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
