{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 ChatOpenAI를 활용한 LLM 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 파일(.env) 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI 라이브러리 불러오기\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ChatOpenAI 모델 초기화 (gpt-4o-mini 모델 사용)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='RAG (Retrieval-Augmented Generation) Pipeline은 자연어 처리(NLP)에서 정보 검색과 생성 모델을 결합한 방법론입니다. 이 접근 방식은 다음과 같은 주요 구성 요소로 이루어져 있습니다.\n",
       "\n",
       "1. **정보 검색 (Retrieval)**: 사용자가 질문을 입력하면, 관련된 정보를 데이터베이스나 문서 집합에서 검색합니다. 이 단계에서는 일반적으로 BM25와 같은 정보 검색 알고리즘이나 딥러닝 기반의 검색 모델이 사용됩니다.\n",
       "\n",
       "2. **정보 생성 (Generation)**: 검색된 정보를 바탕으로, 생성 모델(예: Transformer 기반의 모델, GPT 등)이 질문에 대한 답변을 생성합니다. 이 단계에서는 검색된 정보를 사용하여 보다 자연스럽고 관련성 높은 응답을 만들어냅니다.\n",
       "\n",
       "이러한 RAG 파이프라인의 장점은 다음과 같습니다:\n",
       "\n",
       "- **정확성 향상**: 검색된 정보를 활용함으로써 모델이 보다 정확하고 사실에 기반한 답변을 제공할 수 있습니다.\n",
       "- **지식 업데이트 용이**: 외부 데이터베이스를 사용하여 최신 정보를 쉽게 반영할 수 있어, 모델의 지식이 지속적으로 업데이트될 수 있습니다.\n",
       "- **다양한 응답 가능**: 다양한 출처에서 정보를 가져와 보다 풍부하고 다양한 응답을 생성할 수 있습니다.\n",
       "\n",
       "RAG 파이프라인은 질문 응답 시스템, 대화형 AI, 그리고 정보 검색 기반의 다양한 애플리케이션에서 활용될 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 15, 'total_tokens': 326, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_e2bde53e6e', 'finish_reason': 'stop', 'logprobs': None}, id='run-756e5f10-0437-464a-ac49-e160fb2cddae-0', usage_metadata={'input_tokens': 15, 'output_tokens': 311, 'total_tokens': 326, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM에 질문하고 응답 생성\n",
    "ai_message = llm.invoke(\"RAG 파이프라인은 무엇인가요?\")\n",
    "# 생성된 응답 출력\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
