{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8-1 ChatOllama를 활용한 LLM 답변 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qj/q193qt6n5blc2wppqrq7477r0000gn/T/ipykernel_41450/4108171166.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"exaone3.5:2.4b\")\n"
     ]
    }
   ],
   "source": [
    "# ChatOllama 라이브러리 불러오기\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# ChatOllama 모델 초기화 (exaone3.5:2.4b 모델 사용)\n",
    "llm = ChatOllama(model=\"exaone3.5:2.4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM에 질문하고 응답 생성\n",
    "ai_message = llm.invoke(\"RAG 파이프라인은 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='RAG (Robust Adversarial Generative) Pipeline은 LG AI Research에서 개발한 고성능 언어 모델 학습 및 추론 프레임워크입니다. 이 파이프라인의 주요 특징은 다음과 같습니다:\\n\\n1. **대규모 데이터셋 학습**: RAG Pipeline은 대규모 언어 모델을 훈련시키는 데 사용되며, 주로 자연어 처리(NLP) 작업에 적용됩니다.\\n   \\n2. **다중 모달 처리**: 텍스트뿐만 아니라 이미지와 같은 다양한 모달리티(입력 형식)를 처리하도록 설계되어 있어, 더 포괄적이고 맥락에 맞는 정보 추출이 가능합니다.\\n\\n3. **Query-Based Generation**: 사용자의 질문(Query)에 따라 모델이 관련 답변을 생성하는 방식으로 작동합니다. 이는 특정 주제나 질문에 대한 맞춤형 정보 제공에 유용합니다.\\n\\n4. **Adversarial Training Enhancements**: 적대적 훈련 기법을 통합하여 모델의 안정성과 성능을 향상시킵니다. 이는 모델이 다양한 불확실성 상황에서도 안정적으로 작동하도록 돕습니다.\\n\\n5. **Ethical Considerations**: 개발 과정에서 윤리적 측면을 중시하여 편향성 감소와 공정성을 강화합니다.\\n\\n이러한 특징들로 인해 RAG Pipeline은 특히 대규모 언어 모델 기반 애플리케이션에서 강력한 도구로 활용되고 있습니다.', additional_kwargs={}, response_metadata={'model': 'exaone3.5:2.4b', 'created_at': '2025-02-05T05:52:56.051765Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 6824654208, 'load_duration': 546934208, 'prompt_eval_count': 42, 'prompt_eval_duration': 1860000000, 'eval_count': 299, 'eval_duration': 4271000000}, id='run-dd5c685f-9e64-4751-bbd7-a864f68ad788-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 응답 출력\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
