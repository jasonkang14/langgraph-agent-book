{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29-2 LLM Judge를 활용한 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 평가에 활용할 모델 선언\n",
    "judge_llm = init_chat_model(\"gpt-4o\")\n",
    "\n",
    "async def correct(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    # LLM에게 주는 지시사항 정의\n",
    "    # 실제 답변과 기대 답변을 비교하여\n",
    "    # 모든 정보가 포함되어 있는지 확인하도록 한다.\n",
    "    instructions = (\n",
    "        \"Given an actual answer and an expected answer, determine whether\"\n",
    "        \" the actual answer contains all of the information in the\"\n",
    "        \" expected answer. Respond with 'CORRECT' if the actual answer\"\n",
    "        \" does contain all of the expected information and 'INCORRECT'\"\n",
    "        \" otherwise. Do not include anything else in your response.\"\n",
    "    )\n",
    "    \n",
    "    # 그래프는 State 딕셔너리를 리턴하며\n",
    "    # 'messages' 키가 있고 마지막 메시지가 AI의 최종 답변이 된다.\n",
    "    actual_answer = outputs[\"messages\"][-1].content\n",
    "    expected_answer = reference_outputs[\"answer\"]\n",
    "    \n",
    "    # LLM에게 전달할 메시지 구성\n",
    "    # 실제 답변과 기대 답변을 명확히 구분하여 제시\n",
    "    user_msg = (\n",
    "        f\"ACTUAL ANSWER: {actual_answer}\"\n",
    "        f\"\\n\\nEXPECTED ANSWER: {expected_answer}\"\n",
    "    )\n",
    "    \n",
    "    # LLM 호출하여 답변 평가\n",
    "    # system과 user 역할의 메시지를 함께 전달\n",
    "    response = await judge_llm.ainvoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": instructions},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # LLM의 응답이 'CORRECT'인지 확인하여 결과 반환\n",
    "    return response.content.upper() == \"CORRECT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain Hub에서 환각 평가를 위한 프롬프트 템플릿 가져오기\n",
    "from langchain import hub\n",
    "\n",
    "# RAG 시스템의 답변 환각 평가하기 위한 프롬프트 템플릿 로드\n",
    "grade_prompt_hallucinations = prompt = hub.pull(\"langchain-ai/rag-answer-hallucination\")\n",
    "\n",
    "async def hallucination(outputs) -> dict:\n",
    "    # LLM의 최종 답변과 컨텍스트 추출\n",
    "    # messages 리스트의 구조:\n",
    "    # - 마지막 메시지(-1): LLM의 최종 답변\n",
    "    # - 마지막에서 두 번째 메시지(-2): retrieval_tool의 실행 결과로 얻은 법조문 컨텍스트\n",
    "    # 이는 RAG 파이프라인에서 retrieval_tool이 먼저 실행되고, 그 결과를 바탕으로 LLM이 답변을 생성하기 때문이다.\n",
    "    context = outputs[\"messages\"][-2].content\n",
    "    actual_answer = outputs[\"messages\"][-1].content\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 프롬프트 템플릿과 LLM을 연결하여 평가 파이프라인 구성\n",
    "    # `prompt | llm | StrOutputParser()`` 의 구조와 유사하다.\n",
    "    answer_grader = grade_prompt_hallucinations | judge_llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    # 컨텍스트와 실제 답변을 입력으로 하여 환각 점수 계산\n",
    "    # 환각 점수는 0~1 사이의 값으로, 1에 가까울수록 컨텍스트에 충실한 답변을 의미\n",
    "    score = answer_grader.invoke({\"documents\": [context],\n",
    "                                  \"student_answer\": actual_answer})\n",
    "    # 점수만 추출\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    # 평가 결과를 딕셔너리 형태로 반환\n",
    "    # key: 평가 항목 이름, score: 환각 점수\n",
    "    return score == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkang/personal/langgraph-book/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-4o-470343d4' at:\n",
      "https://smith.langchain.com/o/0c1355d3-1674-4800-b34c-a6eadd4860d5/datasets/ce85bc47-501b-41d3-be3a-9ab56f1524bd/compare?selectedSessions=1c09caa6-d5fe-4371-93f3-17f1bd3b8159\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10f6837a0>\n",
      "1it [00:17, 17.22s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10ce1a960>\n",
      "3it [00:36, 11.60s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x1291b7920>\n",
      "4it [00:48, 11.50s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fcf8ad0>\n",
      "5it [00:57, 10.54s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fe0c110>\n",
      "7it [01:16,  9.88s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fe521b0>\n",
      "8it [01:26,  9.98s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fe50ec0>\n",
      "9it [01:37, 10.49s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fe89ca0>\n",
      "10it [01:46,  9.75s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fe342c0>\n",
      "11it [01:58, 10.44s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fef3da0>\n",
      "12it [02:12, 11.55s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10feff830>\n",
      "13it [02:25, 12.06s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10fef3620>\n",
      "14it [02:42, 13.57s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x12884d730>\n",
      "15it [02:53, 12.92s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x128870110>\n",
      "16it [03:04, 12.19s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x1288a7b90>\n",
      "17it [03:16, 12.17s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x1288a4ad0>\n",
      "18it [03:28, 12.13s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x12884ea80>\n",
      "19it [03:45, 13.74s/it]Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10feb28d0>\n",
      "20it [04:06, 12.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# LangSmith의 비동기 평가 함수와 소득세 에이전트 임포트\n",
    "from langsmith import aevaluate\n",
    "from income_tax_agent import income_tax_agent\n",
    "\n",
    "# 입력 예제를 State 형식으로 변환하는 함수\n",
    "# 사용자 질문을 messages 리스트에 추가하여 초기 상태 생성\n",
    "def example_to_state(inputs: dict) -> dict:\n",
    "  return {\"messages\": [{\"role\": \"user\", \"content\": inputs['question']}]}\n",
    "\n",
    "# LCEL 선언적 구문을 사용하여 파이프라인 구성\n",
    "# example_to_state의 출력을 income_tax_agent의 입력으로 연결\n",
    "# langgraph 그래프는 langchain runnable이기 때문에 가능하다.\n",
    "target = example_to_state | income_tax_agent\n",
    "\n",
    "# 비동기 평가 실행\n",
    "# target: 평가할 파이프라인\n",
    "# data: 평가에 사용할 데이터셋 이름\n",
    "# evaluators: 평가에 사용할 평가 함수 리스트 (correct 함수 사용)\n",
    "experiment_results = await aevaluate(\n",
    "    target,\n",
    "    data=\"income_tax_dataset\",\n",
    "    evaluators=[correct, hallucination],\n",
    "    experiment_prefix='gpt-4o',\n",
    "    description='1.0.1 운영 배포 전 최종 점검'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
